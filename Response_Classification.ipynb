{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Response_Classification.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NW84dI3i60tZ"
      },
      "source": [
        "# **Question Answer Classification**\n",
        "\n",
        "Please run on Google colab and upload the training and testing files."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EXa8Up_062rO",
        "outputId": "6e0f569d-8c5f-446b-86b7-cc38150218f8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 627
        }
      },
      "source": [
        "## Download model and dataset\n",
        "import nltk\n",
        "!python -m spacy download en_core_web_lg\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('vader_lexicon')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: en_core_web_lg==2.2.5 from https://github.com/explosion/spacy-models/releases/download/en_core_web_lg-2.2.5/en_core_web_lg-2.2.5.tar.gz#egg=en_core_web_lg==2.2.5 in /usr/local/lib/python3.6/dist-packages (2.2.5)\n",
            "Requirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.6/dist-packages (from en_core_web_lg==2.2.5) (2.2.4)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (4.41.1)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (1.18.5)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (1.0.2)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (2.0.3)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (0.4.1)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (0.8.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (50.3.0)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (1.1.3)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (3.0.2)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (1.0.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (2.23.0)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (1.0.2)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (7.4.0)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_lg==2.2.5) (2.0.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_lg==2.2.5) (2020.6.20)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_lg==2.2.5) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_lg==2.2.5) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_lg==2.2.5) (3.0.4)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_lg==2.2.5) (3.2.0)\n",
            "\u001b[38;5;2mâœ” Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('en_core_web_lg')\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n",
            "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c7FtuWelO7ha"
      },
      "source": [
        "## Import Libraries\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import spacy\n",
        "import nltk\n",
        "import en_core_web_lg\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.naive_bayes import GaussianNB, MultinomialNB\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from warnings import filterwarnings\n",
        "filterwarnings('ignore')\n",
        "from sklearn.decomposition import PCA\n",
        "from nltk import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.metrics import confusion_matrix,classification_report\n",
        "\n",
        "stop_words=stopwords.words('english')\n",
        "nlp=en_core_web_lg.load()"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CA7bQkYe8GWE"
      },
      "source": [
        "### Read Datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wBpFtc_un3gz",
        "outputId": "354e2919-d891-4dd9-8a52-f0ab0efedcca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        }
      },
      "source": [
        "## Read the dataset\n",
        "train_df=pd.read_csv(\"p2_train.csv\")\n",
        "test_df=pd.read_csv(\"p2_test.csv\")\n",
        "train_size=len(train_df)\n",
        "## Concatenate the train and test dataset to preprocess and generate features\n",
        "df=pd.concat([train_df,test_df],axis=0)\n",
        "df=df[['precedent','subsequent','question','response','type']]\n",
        "df.head()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>precedent</th>\n",
              "      <th>subsequent</th>\n",
              "      <th>question</th>\n",
              "      <th>response</th>\n",
              "      <th>type</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>The most dangerous &lt;&amp;quot;&gt;neighborhood&lt;&amp;quot;...</td>\n",
              "      <td>At least 1/2 of these deaths are gang related....</td>\n",
              "      <td>Should all the blacks in the state move out?</td>\n",
              "      <td>I can't make decisions for other people. But I...</td>\n",
              "      <td>answered</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Riiiiiiiight.</td>\n",
              "      <td>&amp;gt;To claim that hip-hop only spreads a deli...</td>\n",
              "      <td>So, correct me if I'm wrong, but what you're s...</td>\n",
              "      <td>\\nGive me an example of another depiction.</td>\n",
              "      <td>attacked</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Time? Money?</td>\n",
              "      <td>At one point you have to prioritize.</td>\n",
              "      <td>What about the all country?</td>\n",
              "      <td>And how is a critic going to help you do that ...</td>\n",
              "      <td>attacked</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>&amp;gt; And there is no connotation, look up sta...</td>\n",
              "      <td>By not including any other group that is stati...</td>\n",
              "      <td>And men commit more crimes than women, ages 20...</td>\n",
              "      <td>It's like that, but citizens have an entitleme...</td>\n",
              "      <td>answered</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>What the fuck does that even mean?</td>\n",
              "      <td>Can you demonstrate where Quinn slept with so...</td>\n",
              "      <td>How is that Quinn's fault?</td>\n",
              "      <td>It's not Quinn's fault. But for defending Quin...</td>\n",
              "      <td>answered</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                           precedent  ...      type\n",
              "0  The most dangerous <&quot;>neighborhood<&quot;...  ...  answered\n",
              "1                                      Riiiiiiiight.  ...  attacked\n",
              "2                                       Time? Money?  ...  attacked\n",
              "3   &gt; And there is no connotation, look up sta...  ...  answered\n",
              "4                 What the fuck does that even mean?  ...  answered\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ry_h0vQV__SQ"
      },
      "source": [
        "## Preprocessing Features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "poLR785NpRkN",
        "outputId": "fd3dffb7-6f3a-4874-aef4-f2033f9ec5df",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        }
      },
      "source": [
        "## Preprocessing the questions and response\n",
        "## Removes special symbols and lower cases \n",
        "\n",
        "def preprocessing(df,col):\n",
        " \n",
        "  df[col]=df[col].replace('<&quot;>',\"\",regex=True) \n",
        "  df[col]=df[col].str.lower()\n",
        "  df[col]=df[col].replace('\\n','', regex=True)\n",
        "  df[col]=df[col].str.strip()\n",
        "  df[col]=df[col].str.replace('[^\\w\\s\\?]','')\n",
        "  df[col]=df[col].str.replace('$','')\n",
        "  df[col]=df[col].str.replace('.','')\n",
        "  return df\n",
        "\n",
        "df=preprocessing(df,'question')\n",
        "df=preprocessing(df,'response')\n",
        "df.head()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>precedent</th>\n",
              "      <th>subsequent</th>\n",
              "      <th>question</th>\n",
              "      <th>response</th>\n",
              "      <th>type</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>The most dangerous &lt;&amp;quot;&gt;neighborhood&lt;&amp;quot;...</td>\n",
              "      <td>At least 1/2 of these deaths are gang related....</td>\n",
              "      <td>should all the blacks in the state move out?</td>\n",
              "      <td>i cant make decisions for other people but i c...</td>\n",
              "      <td>answered</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Riiiiiiiight.</td>\n",
              "      <td>&amp;gt;To claim that hip-hop only spreads a deli...</td>\n",
              "      <td>so correct me if im wrong but what youre sayin...</td>\n",
              "      <td>give me an example of another depiction</td>\n",
              "      <td>attacked</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Time? Money?</td>\n",
              "      <td>At one point you have to prioritize.</td>\n",
              "      <td>what about the all country?</td>\n",
              "      <td>and how is a critic going to help you do that ...</td>\n",
              "      <td>attacked</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>&amp;gt; And there is no connotation, look up sta...</td>\n",
              "      <td>By not including any other group that is stati...</td>\n",
              "      <td>and men commit more crimes than women ages 20 ...</td>\n",
              "      <td>its like that but citizens have an entitlement...</td>\n",
              "      <td>answered</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>What the fuck does that even mean?</td>\n",
              "      <td>Can you demonstrate where Quinn slept with so...</td>\n",
              "      <td>how is that quinns fault?</td>\n",
              "      <td>its not quinns fault but for defending quinn i...</td>\n",
              "      <td>answered</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                           precedent  ...      type\n",
              "0  The most dangerous <&quot;>neighborhood<&quot;...  ...  answered\n",
              "1                                      Riiiiiiiight.  ...  attacked\n",
              "2                                       Time? Money?  ...  attacked\n",
              "3   &gt; And there is no connotation, look up sta...  ...  answered\n",
              "4                 What the fuck does that even mean?  ...  answered\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hHNS3WURAZdh"
      },
      "source": [
        "## Baseline Features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7HmbJDehHMx9",
        "outputId": "392db2bd-5a60-42ad-e116-5d7a70bf1d54",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 638
        }
      },
      "source": [
        "## Sentence Vector Representation \n",
        "'''\n",
        "question_vector_rep - vector representation of question\n",
        "response_vector_rep - vector representation of response\n",
        "vector - vector represenation of both question and response\n",
        "'''\n",
        "\n",
        "def vector_representation(sentence):\n",
        "    doc=nlp(sentence)\n",
        "    vector=doc.vector\n",
        "    return vector\n",
        "\n",
        "def get_vectors(df,col):\n",
        "    df[col+'_vector_rep']=df[col].apply(lambda x: vector_representation(x))\n",
        "    return df\n",
        "\n",
        "## Get vector represenation of question and response\n",
        "vectors_df=get_vectors(df,'question')\n",
        "vectors_df=get_vectors(df,'response')\n",
        "\n",
        "## Concatenate the question and response vectors\n",
        "vectors=[]\n",
        "question_vectors=df['question_vector_rep'].tolist()\n",
        "response_vectors=df['response_vector_rep'].tolist()\n",
        "\n",
        "for i in range(len(question_vectors)):\n",
        "  vector=np.concatenate((question_vectors[i],response_vectors[i]),axis=None)\n",
        "  vectors.append(vector)\n",
        "\n",
        "\n",
        "vectors_df['vector']=vectors\n",
        "\n",
        "## Convert categorical labels into Integer representation\n",
        "## {0: answered, 1: attacked ,2: irrelevant, 3: agreed}\n",
        "vectors_df.type = pd.Categorical(pd.factorize(vectors_df.type)[0])\n",
        "\n",
        "## The embeddings are in 600 dimensional after concatenating. We can reduce this high dimensions \n",
        "## into lower dimension by dimensionality reduction methods. We ensure that it captures 75-90% variance in the data\n",
        "\n",
        "pca=PCA(n_components=60)\n",
        "pca_res=pca.fit_transform(vectors)\n",
        "l=[]\n",
        "for i in pca_res:\n",
        "  l.append(np.array(i)) \n",
        "vectors_df['vector']=l\n",
        "vectors_df.head()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>precedent</th>\n",
              "      <th>subsequent</th>\n",
              "      <th>question</th>\n",
              "      <th>response</th>\n",
              "      <th>type</th>\n",
              "      <th>question_vector_rep</th>\n",
              "      <th>response_vector_rep</th>\n",
              "      <th>vector</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>The most dangerous &lt;&amp;quot;&gt;neighborhood&lt;&amp;quot;...</td>\n",
              "      <td>At least 1/2 of these deaths are gang related....</td>\n",
              "      <td>should all the blacks in the state move out?</td>\n",
              "      <td>i cant make decisions for other people but i c...</td>\n",
              "      <td>0</td>\n",
              "      <td>[0.04330626, 0.045562994, -0.016042003, -0.148...</td>\n",
              "      <td>[-0.083568744, 0.15506375, -0.23541515, -0.054...</td>\n",
              "      <td>[-0.5864192303622856, -0.022218359114974773, 0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Riiiiiiiight.</td>\n",
              "      <td>&amp;gt;To claim that hip-hop only spreads a deli...</td>\n",
              "      <td>so correct me if im wrong but what youre sayin...</td>\n",
              "      <td>give me an example of another depiction</td>\n",
              "      <td>1</td>\n",
              "      <td>[-0.047989298, 0.14819294, -0.2549167, -0.1186...</td>\n",
              "      <td>[-0.15461029, 0.15779972, -0.18892084, 0.15702...</td>\n",
              "      <td>[-0.08770394395260009, 0.13676199650971663, -0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Time? Money?</td>\n",
              "      <td>At one point you have to prioritize.</td>\n",
              "      <td>what about the all country?</td>\n",
              "      <td>and how is a critic going to help you do that ...</td>\n",
              "      <td>1</td>\n",
              "      <td>[-0.0005612299, 0.28547665, -0.08796167, -0.17...</td>\n",
              "      <td>[-0.045013502, 0.1485028, -0.25629047, -0.0049...</td>\n",
              "      <td>[0.09976164830915897, -0.17617712717874473, 0....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>&amp;gt; And there is no connotation, look up sta...</td>\n",
              "      <td>By not including any other group that is stati...</td>\n",
              "      <td>and men commit more crimes than women ages 20 ...</td>\n",
              "      <td>its like that but citizens have an entitlement...</td>\n",
              "      <td>0</td>\n",
              "      <td>[-0.12268909, 0.15060432, -0.08220947, -0.1092...</td>\n",
              "      <td>[-0.015303677, 0.07679086, -0.13528888, -0.083...</td>\n",
              "      <td>[-0.6706652955257439, 0.13793602850620543, -0....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>What the fuck does that even mean?</td>\n",
              "      <td>Can you demonstrate where Quinn slept with so...</td>\n",
              "      <td>how is that quinns fault?</td>\n",
              "      <td>its not quinns fault but for defending quinn i...</td>\n",
              "      <td>0</td>\n",
              "      <td>[-0.090715826, 0.17173333, -0.03452379, -0.105...</td>\n",
              "      <td>[-0.15782003, 0.11515223, -0.16754769, 0.00083...</td>\n",
              "      <td>[0.4266863824720189, 0.4956174718237338, 0.504...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                           precedent  ...                                             vector\n",
              "0  The most dangerous <&quot;>neighborhood<&quot;...  ...  [-0.5864192303622856, -0.022218359114974773, 0...\n",
              "1                                      Riiiiiiiight.  ...  [-0.08770394395260009, 0.13676199650971663, -0...\n",
              "2                                       Time? Money?  ...  [0.09976164830915897, -0.17617712717874473, 0....\n",
              "3   &gt; And there is no connotation, look up sta...  ...  [-0.6706652955257439, 0.13793602850620543, -0....\n",
              "4                 What the fuck does that even mean?  ...  [0.4266863824720189, 0.4956174718237338, 0.504...\n",
              "\n",
              "[5 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A10RH0HXCJGE",
        "outputId": "eadb16cc-03bc-4a92-dee6-6773f239f1c8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 849
        }
      },
      "source": [
        "## Modeling with only embeddings feature\n",
        "train_X,train_Y = vectors_df['vector'].iloc[:train_size],vectors_df['type'].iloc[:train_size]\n",
        "test_X,test_Y = vectors_df['vector'].iloc[train_size:],vectors_df['type'].iloc[train_size:]\n",
        "\n",
        "model_SVC = LinearSVC(class_weight='balanced')\n",
        "model_LR=LogisticRegression()\n",
        "model_NB = GaussianNB()\n",
        "\n",
        "model_NB.fit(train_X.tolist(), train_Y)\n",
        "model_SVC.fit(train_X.tolist(), train_Y)\n",
        "model_LR.fit(train_X.tolist(),train_Y)\n",
        "\n",
        "predicted_labels_SVC = model_SVC.predict(test_X.tolist())\n",
        "predicted_labels_NB = model_NB.predict(test_X.tolist())\n",
        "predicted_labels_LR = model_LR.predict(test_X.tolist())\n",
        "\n",
        "print (\"SVC Report\")\n",
        "print (confusion_matrix(test_Y,predicted_labels_SVC))\n",
        "print (classification_report(test_Y,predicted_labels_SVC))\n",
        "\n",
        "print (\"Naive Bayes\")\n",
        "print (confusion_matrix(test_Y,predicted_labels_NB))\n",
        "print (classification_report(test_Y,predicted_labels_NB))\n",
        "\n",
        "print (\"LR Report\")\n",
        "print (confusion_matrix(test_Y,predicted_labels_LR))\n",
        "print (classification_report(test_Y,predicted_labels_LR))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "SVC Report\n",
            "[[246  26  28  20]\n",
            " [ 12  16   8   3]\n",
            " [ 14  10  12   2]\n",
            " [  7   0   0   6]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.77      0.82       320\n",
            "           1       0.31      0.41      0.35        39\n",
            "           2       0.25      0.32      0.28        38\n",
            "           3       0.19      0.46      0.27        13\n",
            "\n",
            "    accuracy                           0.68       410\n",
            "   macro avg       0.41      0.49      0.43       410\n",
            "weighted avg       0.75      0.68      0.71       410\n",
            "\n",
            "Naive Bayes\n",
            "[[180  95  41   4]\n",
            " [ 17  16   4   2]\n",
            " [ 17   9  11   1]\n",
            " [  5   3   4   1]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      0.56      0.67       320\n",
            "           1       0.13      0.41      0.20        39\n",
            "           2       0.18      0.29      0.22        38\n",
            "           3       0.12      0.08      0.10        13\n",
            "\n",
            "    accuracy                           0.51       410\n",
            "   macro avg       0.32      0.33      0.30       410\n",
            "weighted avg       0.67      0.51      0.56       410\n",
            "\n",
            "LR Report\n",
            "[[305   8   6   1]\n",
            " [ 27  10   2   0]\n",
            " [ 24   7   7   0]\n",
            " [ 10   0   1   2]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.95      0.89       320\n",
            "           1       0.40      0.26      0.31        39\n",
            "           2       0.44      0.18      0.26        38\n",
            "           3       0.67      0.15      0.25        13\n",
            "\n",
            "    accuracy                           0.79       410\n",
            "   macro avg       0.58      0.39      0.43       410\n",
            "weighted avg       0.75      0.79      0.76       410\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ou8PzJC5hHtr",
        "outputId": "c309c420-50cc-47ad-caa5-26b5a3dc7f9a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "## POS Tagging Features\n",
        "## Generate pos tags for both questions and responses\n",
        "'''\n",
        "question_pos_rep - Pos tag representations of questions\n",
        "response_pos_rep - Pos tag representations of responses\n",
        "pos-tags - Concatenation of both vectors\n",
        "'''\n",
        "\n",
        "def pos_tags_representation(sentence):\n",
        "  if len(sentence)!=0:\n",
        "    \n",
        "    tagged_tokens=nltk.pos_tag(sentence.split())\n",
        "    words,tags=zip(*tagged_tokens)\n",
        "    return list(tags)\n",
        "  else:\n",
        "    return []\n",
        "\n",
        "def get_pos_tags(df,col):\n",
        "  df[col+'_postag_rep']=df[col].apply(lambda x: pos_tags_representation(x))\n",
        "  return df\n",
        "\n",
        "\n",
        "# Concatenate the pos tags of both question and respone sentences\n",
        "def concatenate_tags():\n",
        "  tags_df=get_pos_tags(vectors_df,'question')\n",
        "  tags_df=get_pos_tags(vectors_df,'response')\n",
        "  tags_df['pos-tags']=tags_df['question_postag_rep']+tags_df['response_postag_rep']\n",
        "  return tags_df\n",
        "\n",
        "tags_df=concatenate_tags()\n",
        "tags_df.head()\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>precedent</th>\n",
              "      <th>subsequent</th>\n",
              "      <th>question</th>\n",
              "      <th>response</th>\n",
              "      <th>type</th>\n",
              "      <th>question_vector_rep</th>\n",
              "      <th>response_vector_rep</th>\n",
              "      <th>vector</th>\n",
              "      <th>question_postag_rep</th>\n",
              "      <th>response_postag_rep</th>\n",
              "      <th>pos-tags</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>The most dangerous &lt;&amp;quot;&gt;neighborhood&lt;&amp;quot;...</td>\n",
              "      <td>At least 1/2 of these deaths are gang related....</td>\n",
              "      <td>should all the blacks in the state move out?</td>\n",
              "      <td>i cant make decisions for other people but i c...</td>\n",
              "      <td>0</td>\n",
              "      <td>[0.04330626, 0.045562994, -0.016042003, -0.148...</td>\n",
              "      <td>[-0.083568744, 0.15506375, -0.23541515, -0.054...</td>\n",
              "      <td>[-0.5864192303622856, -0.022218359114974773, 0...</td>\n",
              "      <td>[MD, PDT, DT, NNS, IN, DT, NN, NN, NN]</td>\n",
              "      <td>[NN, VBP, NN, NNS, IN, JJ, NNS, CC, NN, MD, VB...</td>\n",
              "      <td>[MD, PDT, DT, NNS, IN, DT, NN, NN, NN, NN, VBP...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Riiiiiiiight.</td>\n",
              "      <td>&amp;gt;To claim that hip-hop only spreads a deli...</td>\n",
              "      <td>so correct me if im wrong but what youre sayin...</td>\n",
              "      <td>give me an example of another depiction</td>\n",
              "      <td>1</td>\n",
              "      <td>[-0.047989298, 0.14819294, -0.2549167, -0.1186...</td>\n",
              "      <td>[-0.15461029, 0.15779972, -0.18892084, 0.15702...</td>\n",
              "      <td>[-0.08770394395260009, 0.13676199650971663, -0...</td>\n",
              "      <td>[RB, JJ, PRP, IN, VBN, RB, CC, WP, NN, VBG, VB...</td>\n",
              "      <td>[VB, PRP, DT, NN, IN, DT, NN]</td>\n",
              "      <td>[RB, JJ, PRP, IN, VBN, RB, CC, WP, NN, VBG, VB...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Time? Money?</td>\n",
              "      <td>At one point you have to prioritize.</td>\n",
              "      <td>what about the all country?</td>\n",
              "      <td>and how is a critic going to help you do that ...</td>\n",
              "      <td>1</td>\n",
              "      <td>[-0.0005612299, 0.28547665, -0.08796167, -0.17...</td>\n",
              "      <td>[-0.045013502, 0.1485028, -0.25629047, -0.0049...</td>\n",
              "      <td>[0.09976164830915897, -0.17617712717874473, 0....</td>\n",
              "      <td>[WP, IN, DT, DT, NNS]</td>\n",
              "      <td>[CC, WRB, VBZ, DT, JJ, VBG, TO, VB, PRP, VB, D...</td>\n",
              "      <td>[WP, IN, DT, DT, NNS, CC, WRB, VBZ, DT, JJ, VB...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>&amp;gt; And there is no connotation, look up sta...</td>\n",
              "      <td>By not including any other group that is stati...</td>\n",
              "      <td>and men commit more crimes than women ages 20 ...</td>\n",
              "      <td>its like that but citizens have an entitlement...</td>\n",
              "      <td>0</td>\n",
              "      <td>[-0.12268909, 0.15060432, -0.08220947, -0.1092...</td>\n",
              "      <td>[-0.015303677, 0.07679086, -0.13528888, -0.083...</td>\n",
              "      <td>[-0.6706652955257439, 0.13793602850620543, -0....</td>\n",
              "      <td>[CC, NNS, VBP, JJR, NNS, IN, NNS, VBZ, CD, TO,...</td>\n",
              "      <td>[PRP$, IN, DT, CC, NNS, VBP, DT, NN, IN, NN, I...</td>\n",
              "      <td>[CC, NNS, VBP, JJR, NNS, IN, NNS, VBZ, CD, TO,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>What the fuck does that even mean?</td>\n",
              "      <td>Can you demonstrate where Quinn slept with so...</td>\n",
              "      <td>how is that quinns fault?</td>\n",
              "      <td>its not quinns fault but for defending quinn i...</td>\n",
              "      <td>0</td>\n",
              "      <td>[-0.090715826, 0.17173333, -0.03452379, -0.105...</td>\n",
              "      <td>[-0.15782003, 0.11515223, -0.16754769, 0.00083...</td>\n",
              "      <td>[0.4266863824720189, 0.4956174718237338, 0.504...</td>\n",
              "      <td>[WRB, VBZ, IN, NN, NN]</td>\n",
              "      <td>[PRP$, RB, JJ, NN, CC, IN, VBG, NN, IN, NNS, W...</td>\n",
              "      <td>[WRB, VBZ, IN, NN, NN, PRP$, RB, JJ, NN, CC, I...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                           precedent  ...                                           pos-tags\n",
              "0  The most dangerous <&quot;>neighborhood<&quot;...  ...  [MD, PDT, DT, NNS, IN, DT, NN, NN, NN, NN, VBP...\n",
              "1                                      Riiiiiiiight.  ...  [RB, JJ, PRP, IN, VBN, RB, CC, WP, NN, VBG, VB...\n",
              "2                                       Time? Money?  ...  [WP, IN, DT, DT, NNS, CC, WRB, VBZ, DT, JJ, VB...\n",
              "3   &gt; And there is no connotation, look up sta...  ...  [CC, NNS, VBP, JJR, NNS, IN, NNS, VBZ, CD, TO,...\n",
              "4                 What the fuck does that even mean?  ...  [WRB, VBZ, IN, NN, NN, PRP$, RB, JJ, NN, CC, I...\n",
              "\n",
              "[5 rows x 11 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "otlGJD6xe4e7",
        "outputId": "03f5f714-adb1-46ae-d9c2-23df0470d3c7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "## Create count vector representation for pos tags\n",
        "\n",
        "## Create a mapping for the pos_tags so that number of diffent type of pos tags are represented by count vectorizer\n",
        "all_tags=[]\n",
        "for i in range(len(tags_df)):  \n",
        "  all_tags+=(tags_df['pos-tags'].iloc[i])\n",
        "tags_list=list(set(all_tags))\n",
        "mapping={}\n",
        "for i in range(len(tags_list)):\n",
        "  mapping[tags_list[i]]=i\n",
        "\n",
        "def pos_vector_mapping(pos_list):\n",
        "  one_hot=np.zeros(len(mapping))\n",
        "  for i in pos_list:\n",
        "    one_hot[mapping[i]]+=1\n",
        "\n",
        "  return one_hot  \n",
        "\n",
        "tags_df['pos_tag_vector']=df['pos-tags'].apply(lambda x: pos_vector_mapping(x))\n",
        "tags_df.head()\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>precedent</th>\n",
              "      <th>subsequent</th>\n",
              "      <th>question</th>\n",
              "      <th>response</th>\n",
              "      <th>type</th>\n",
              "      <th>question_vector_rep</th>\n",
              "      <th>response_vector_rep</th>\n",
              "      <th>vector</th>\n",
              "      <th>question_postag_rep</th>\n",
              "      <th>response_postag_rep</th>\n",
              "      <th>pos-tags</th>\n",
              "      <th>pos_tag_vector</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>The most dangerous &lt;&amp;quot;&gt;neighborhood&lt;&amp;quot;...</td>\n",
              "      <td>At least 1/2 of these deaths are gang related....</td>\n",
              "      <td>should all the blacks in the state move out?</td>\n",
              "      <td>i cant make decisions for other people but i c...</td>\n",
              "      <td>0</td>\n",
              "      <td>[0.04330626, 0.045562994, -0.016042003, -0.148...</td>\n",
              "      <td>[-0.083568744, 0.15506375, -0.23541515, -0.054...</td>\n",
              "      <td>[-0.5864192303622856, -0.022218359114974773, 0...</td>\n",
              "      <td>[MD, PDT, DT, NNS, IN, DT, NN, NN, NN]</td>\n",
              "      <td>[NN, VBP, NN, NNS, IN, JJ, NNS, CC, NN, MD, VB...</td>\n",
              "      <td>[MD, PDT, DT, NNS, IN, DT, NN, NN, NN, NN, VBP...</td>\n",
              "      <td>[5.0, 1.0, 1.0, 6.0, 1.0, 12.0, 0.0, 0.0, 6.0,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Riiiiiiiight.</td>\n",
              "      <td>&amp;gt;To claim that hip-hop only spreads a deli...</td>\n",
              "      <td>so correct me if im wrong but what youre sayin...</td>\n",
              "      <td>give me an example of another depiction</td>\n",
              "      <td>1</td>\n",
              "      <td>[-0.047989298, 0.14819294, -0.2549167, -0.1186...</td>\n",
              "      <td>[-0.15461029, 0.15779972, -0.18892084, 0.15702...</td>\n",
              "      <td>[-0.08770394395260009, 0.13676199650971663, -0...</td>\n",
              "      <td>[RB, JJ, PRP, IN, VBN, RB, CC, WP, NN, VBG, VB...</td>\n",
              "      <td>[VB, PRP, DT, NN, IN, DT, NN]</td>\n",
              "      <td>[RB, JJ, PRP, IN, VBN, RB, CC, WP, NN, VBG, VB...</td>\n",
              "      <td>[1.0, 0.0, 0.0, 5.0, 2.0, 6.0, 0.0, 0.0, 1.0, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Time? Money?</td>\n",
              "      <td>At one point you have to prioritize.</td>\n",
              "      <td>what about the all country?</td>\n",
              "      <td>and how is a critic going to help you do that ...</td>\n",
              "      <td>1</td>\n",
              "      <td>[-0.0005612299, 0.28547665, -0.08796167, -0.17...</td>\n",
              "      <td>[-0.045013502, 0.1485028, -0.25629047, -0.0049...</td>\n",
              "      <td>[0.09976164830915897, -0.17617712717874473, 0....</td>\n",
              "      <td>[WP, IN, DT, DT, NNS]</td>\n",
              "      <td>[CC, WRB, VBZ, DT, JJ, VBG, TO, VB, PRP, VB, D...</td>\n",
              "      <td>[WP, IN, DT, DT, NNS, CC, WRB, VBZ, DT, JJ, VB...</td>\n",
              "      <td>[1.0, 1.0, 1.0, 6.0, 1.0, 2.0, 0.0, 0.0, 2.0, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>&amp;gt; And there is no connotation, look up sta...</td>\n",
              "      <td>By not including any other group that is stati...</td>\n",
              "      <td>and men commit more crimes than women ages 20 ...</td>\n",
              "      <td>its like that but citizens have an entitlement...</td>\n",
              "      <td>0</td>\n",
              "      <td>[-0.12268909, 0.15060432, -0.08220947, -0.1092...</td>\n",
              "      <td>[-0.015303677, 0.07679086, -0.13528888, -0.083...</td>\n",
              "      <td>[-0.6706652955257439, 0.13793602850620543, -0....</td>\n",
              "      <td>[CC, NNS, VBP, JJR, NNS, IN, NNS, VBZ, CD, TO,...</td>\n",
              "      <td>[PRP$, IN, DT, CC, NNS, VBP, DT, NN, IN, NN, I...</td>\n",
              "      <td>[CC, NNS, VBP, JJR, NNS, IN, NNS, VBZ, CD, TO,...</td>\n",
              "      <td>[5.0, 3.0, 3.0, 14.0, 7.0, 15.0, 0.0, 0.0, 5.0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>What the fuck does that even mean?</td>\n",
              "      <td>Can you demonstrate where Quinn slept with so...</td>\n",
              "      <td>how is that quinns fault?</td>\n",
              "      <td>its not quinns fault but for defending quinn i...</td>\n",
              "      <td>0</td>\n",
              "      <td>[-0.090715826, 0.17173333, -0.03452379, -0.105...</td>\n",
              "      <td>[-0.15782003, 0.11515223, -0.16754769, 0.00083...</td>\n",
              "      <td>[0.4266863824720189, 0.4956174718237338, 0.504...</td>\n",
              "      <td>[WRB, VBZ, IN, NN, NN]</td>\n",
              "      <td>[PRP$, RB, JJ, NN, CC, IN, VBG, NN, IN, NNS, W...</td>\n",
              "      <td>[WRB, VBZ, IN, NN, NN, PRP$, RB, JJ, NN, CC, I...</td>\n",
              "      <td>[2.0, 2.0, 1.0, 0.0, 1.0, 6.0, 0.0, 0.0, 0.0, ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                           precedent  ...                                     pos_tag_vector\n",
              "0  The most dangerous <&quot;>neighborhood<&quot;...  ...  [5.0, 1.0, 1.0, 6.0, 1.0, 12.0, 0.0, 0.0, 6.0,...\n",
              "1                                      Riiiiiiiight.  ...  [1.0, 0.0, 0.0, 5.0, 2.0, 6.0, 0.0, 0.0, 1.0, ...\n",
              "2                                       Time? Money?  ...  [1.0, 1.0, 1.0, 6.0, 1.0, 2.0, 0.0, 0.0, 2.0, ...\n",
              "3   &gt; And there is no connotation, look up sta...  ...  [5.0, 3.0, 3.0, 14.0, 7.0, 15.0, 0.0, 0.0, 5.0...\n",
              "4                 What the fuck does that even mean?  ...  [2.0, 2.0, 1.0, 0.0, 1.0, 6.0, 0.0, 0.0, 0.0, ...\n",
              "\n",
              "[5 rows x 12 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "93jtghglLb7H"
      },
      "source": [
        "## Baseline Model with embeddings and pos tags"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vg9hkxSzvYdo",
        "outputId": "04f304d3-a123-4ae9-9c4f-be080e16d2b3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "## Combine both embeddings and pos tags for baseline models\n",
        "word_pos=[]\n",
        "for i in range(len(tags_df)):\n",
        "  word_pos.append(list(tags_df['vector'].iloc[i])+list(tags_df['pos_tag_vector'].iloc[i]))\n",
        "\n",
        "tags_df['word_pos']=word_pos\n",
        "tags_df.head()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>precedent</th>\n",
              "      <th>subsequent</th>\n",
              "      <th>question</th>\n",
              "      <th>response</th>\n",
              "      <th>type</th>\n",
              "      <th>question_vector_rep</th>\n",
              "      <th>response_vector_rep</th>\n",
              "      <th>vector</th>\n",
              "      <th>question_postag_rep</th>\n",
              "      <th>response_postag_rep</th>\n",
              "      <th>pos-tags</th>\n",
              "      <th>pos_tag_vector</th>\n",
              "      <th>word_pos</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>The most dangerous &lt;&amp;quot;&gt;neighborhood&lt;&amp;quot;...</td>\n",
              "      <td>At least 1/2 of these deaths are gang related....</td>\n",
              "      <td>should all the blacks in the state move out?</td>\n",
              "      <td>i cant make decisions for other people but i c...</td>\n",
              "      <td>0</td>\n",
              "      <td>[0.04330626, 0.045562994, -0.016042003, -0.148...</td>\n",
              "      <td>[-0.083568744, 0.15506375, -0.23541515, -0.054...</td>\n",
              "      <td>[-0.5864192303622856, -0.022218359114974773, 0...</td>\n",
              "      <td>[MD, PDT, DT, NNS, IN, DT, NN, NN, NN]</td>\n",
              "      <td>[NN, VBP, NN, NNS, IN, JJ, NNS, CC, NN, MD, VB...</td>\n",
              "      <td>[MD, PDT, DT, NNS, IN, DT, NN, NN, NN, NN, VBP...</td>\n",
              "      <td>[5.0, 1.0, 1.0, 6.0, 1.0, 12.0, 0.0, 0.0, 6.0,...</td>\n",
              "      <td>[-0.5864192303622856, -0.022218359114974773, 0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Riiiiiiiight.</td>\n",
              "      <td>&amp;gt;To claim that hip-hop only spreads a deli...</td>\n",
              "      <td>so correct me if im wrong but what youre sayin...</td>\n",
              "      <td>give me an example of another depiction</td>\n",
              "      <td>1</td>\n",
              "      <td>[-0.047989298, 0.14819294, -0.2549167, -0.1186...</td>\n",
              "      <td>[-0.15461029, 0.15779972, -0.18892084, 0.15702...</td>\n",
              "      <td>[-0.08770394395260009, 0.13676199650971663, -0...</td>\n",
              "      <td>[RB, JJ, PRP, IN, VBN, RB, CC, WP, NN, VBG, VB...</td>\n",
              "      <td>[VB, PRP, DT, NN, IN, DT, NN]</td>\n",
              "      <td>[RB, JJ, PRP, IN, VBN, RB, CC, WP, NN, VBG, VB...</td>\n",
              "      <td>[1.0, 0.0, 0.0, 5.0, 2.0, 6.0, 0.0, 0.0, 1.0, ...</td>\n",
              "      <td>[-0.08770394395260009, 0.13676199650971663, -0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Time? Money?</td>\n",
              "      <td>At one point you have to prioritize.</td>\n",
              "      <td>what about the all country?</td>\n",
              "      <td>and how is a critic going to help you do that ...</td>\n",
              "      <td>1</td>\n",
              "      <td>[-0.0005612299, 0.28547665, -0.08796167, -0.17...</td>\n",
              "      <td>[-0.045013502, 0.1485028, -0.25629047, -0.0049...</td>\n",
              "      <td>[0.09976164830915897, -0.17617712717874473, 0....</td>\n",
              "      <td>[WP, IN, DT, DT, NNS]</td>\n",
              "      <td>[CC, WRB, VBZ, DT, JJ, VBG, TO, VB, PRP, VB, D...</td>\n",
              "      <td>[WP, IN, DT, DT, NNS, CC, WRB, VBZ, DT, JJ, VB...</td>\n",
              "      <td>[1.0, 1.0, 1.0, 6.0, 1.0, 2.0, 0.0, 0.0, 2.0, ...</td>\n",
              "      <td>[0.09976164830915897, -0.17617712717874473, 0....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>&amp;gt; And there is no connotation, look up sta...</td>\n",
              "      <td>By not including any other group that is stati...</td>\n",
              "      <td>and men commit more crimes than women ages 20 ...</td>\n",
              "      <td>its like that but citizens have an entitlement...</td>\n",
              "      <td>0</td>\n",
              "      <td>[-0.12268909, 0.15060432, -0.08220947, -0.1092...</td>\n",
              "      <td>[-0.015303677, 0.07679086, -0.13528888, -0.083...</td>\n",
              "      <td>[-0.6706652955257439, 0.13793602850620543, -0....</td>\n",
              "      <td>[CC, NNS, VBP, JJR, NNS, IN, NNS, VBZ, CD, TO,...</td>\n",
              "      <td>[PRP$, IN, DT, CC, NNS, VBP, DT, NN, IN, NN, I...</td>\n",
              "      <td>[CC, NNS, VBP, JJR, NNS, IN, NNS, VBZ, CD, TO,...</td>\n",
              "      <td>[5.0, 3.0, 3.0, 14.0, 7.0, 15.0, 0.0, 0.0, 5.0...</td>\n",
              "      <td>[-0.6706652955257439, 0.13793602850620543, -0....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>What the fuck does that even mean?</td>\n",
              "      <td>Can you demonstrate where Quinn slept with so...</td>\n",
              "      <td>how is that quinns fault?</td>\n",
              "      <td>its not quinns fault but for defending quinn i...</td>\n",
              "      <td>0</td>\n",
              "      <td>[-0.090715826, 0.17173333, -0.03452379, -0.105...</td>\n",
              "      <td>[-0.15782003, 0.11515223, -0.16754769, 0.00083...</td>\n",
              "      <td>[0.4266863824720189, 0.4956174718237338, 0.504...</td>\n",
              "      <td>[WRB, VBZ, IN, NN, NN]</td>\n",
              "      <td>[PRP$, RB, JJ, NN, CC, IN, VBG, NN, IN, NNS, W...</td>\n",
              "      <td>[WRB, VBZ, IN, NN, NN, PRP$, RB, JJ, NN, CC, I...</td>\n",
              "      <td>[2.0, 2.0, 1.0, 0.0, 1.0, 6.0, 0.0, 0.0, 0.0, ...</td>\n",
              "      <td>[0.4266863824720189, 0.4956174718237338, 0.504...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                           precedent  ...                                           word_pos\n",
              "0  The most dangerous <&quot;>neighborhood<&quot;...  ...  [-0.5864192303622856, -0.022218359114974773, 0...\n",
              "1                                      Riiiiiiiight.  ...  [-0.08770394395260009, 0.13676199650971663, -0...\n",
              "2                                       Time? Money?  ...  [0.09976164830915897, -0.17617712717874473, 0....\n",
              "3   &gt; And there is no connotation, look up sta...  ...  [-0.6706652955257439, 0.13793602850620543, -0....\n",
              "4                 What the fuck does that even mean?  ...  [0.4266863824720189, 0.4956174718237338, 0.504...\n",
              "\n",
              "[5 rows x 13 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F8dbVT4eMnvC",
        "outputId": "ce666624-d07a-4900-b071-4ab3611ded8a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 849
        }
      },
      "source": [
        "\n",
        "\n",
        "## Modeling with only embeddings feature\n",
        "train_X,train_Y = tags_df['word_pos'].iloc[:train_size],tags_df['type'].iloc[:train_size]\n",
        "test_X,test_Y = tags_df['word_pos'].iloc[train_size:],tags_df['type'].iloc[train_size:]\n",
        "\n",
        "model_SVC = LinearSVC(random_state=2,class_weight='balanced')\n",
        "model_LR = LogisticRegression(max_iter=1000)\n",
        "model_KNN = KNeighborsClassifier()\n",
        "\n",
        "model_LR.fit(train_X.tolist(), train_Y)\n",
        "model_SVC.fit(train_X.tolist(), train_Y)\n",
        "model_KNN.fit(train_X.tolist(), train_Y)\n",
        "\n",
        "predicted_labels_SVC = model_SVC.predict(test_X.tolist())\n",
        "predicted_labels_LR = model_LR.predict(test_X.tolist())\n",
        "predicted_labels_KNN = model_KNN.predict(test_X.tolist())\n",
        "\n",
        "print (\"SVC Report\")\n",
        "print (confusion_matrix(test_Y,predicted_labels_SVC))\n",
        "print (classification_report(test_Y,predicted_labels_SVC))\n",
        "\n",
        "print (\"Logistic Regression\")\n",
        "print (confusion_matrix(test_Y,predicted_labels_LR))\n",
        "print (classification_report(test_Y,predicted_labels_LR))\n",
        "\n",
        "print (\"KNN\")\n",
        "print (confusion_matrix(test_Y,predicted_labels_KNN))\n",
        "print (classification_report(test_Y,predicted_labels_KNN))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "SVC Report\n",
            "[[274  14  22  10]\n",
            " [ 19  13   4   3]\n",
            " [ 20   8   9   1]\n",
            " [  8   1   0   4]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.86      0.85       320\n",
            "           1       0.36      0.33      0.35        39\n",
            "           2       0.26      0.24      0.25        38\n",
            "           3       0.22      0.31      0.26        13\n",
            "\n",
            "    accuracy                           0.73       410\n",
            "   macro avg       0.42      0.43      0.43       410\n",
            "weighted avg       0.73      0.73      0.73       410\n",
            "\n",
            "Logistic Regression\n",
            "[[292  12  15   1]\n",
            " [ 25  10   4   0]\n",
            " [ 23   8   7   0]\n",
            " [ 10   0   1   2]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.91      0.87       320\n",
            "           1       0.33      0.26      0.29        39\n",
            "           2       0.26      0.18      0.22        38\n",
            "           3       0.67      0.15      0.25        13\n",
            "\n",
            "    accuracy                           0.76       410\n",
            "   macro avg       0.52      0.38      0.41       410\n",
            "weighted avg       0.73      0.76      0.74       410\n",
            "\n",
            "KNN\n",
            "[[283  26  11   0]\n",
            " [ 29   9   1   0]\n",
            " [ 30   4   4   0]\n",
            " [  9   3   1   0]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.81      0.88      0.84       320\n",
            "           1       0.21      0.23      0.22        39\n",
            "           2       0.24      0.11      0.15        38\n",
            "           3       0.00      0.00      0.00        13\n",
            "\n",
            "    accuracy                           0.72       410\n",
            "   macro avg       0.31      0.31      0.30       410\n",
            "weighted avg       0.67      0.72      0.69       410\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-EOt6B1WSUB_"
      },
      "source": [
        ""
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0KL5NnJjRqKE"
      },
      "source": [
        "## NEW FEATURES"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JDfpg91fvjaj"
      },
      "source": [
        "## Generate sentiment values for the questions and response\n",
        "\n",
        "def sentiment_vector(sentence):\n",
        "  analyser = SentimentIntensityAnalyzer()\n",
        "  score_dict=analyser.polarity_scores(sentence)\n",
        "  return score_dict['compound']\n",
        "\n",
        "\n",
        "tags_df['question_sentiment']=tags_df['question'].apply(lambda x: sentiment_vector(x))\n",
        "tags_df['response_sentiment']=tags_df['response'].apply(lambda x: sentiment_vector(x))\n"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-_-cB00MvuzN"
      },
      "source": [
        "## Genreate cosine similarity between the questions and response\n",
        "\n",
        "def get_cosine_similarity(feature_vec_1, feature_vec_2):    \n",
        "    return cosine_similarity(feature_vec_1.reshape(1, -1), feature_vec_2.reshape(1, -1))[0][0]\n",
        "\n",
        "cosines=[]\n",
        "for i in range(len(tags_df)):\n",
        "  cosines.append(get_cosine_similarity(tags_df['question_vector_rep'].iloc[i],tags_df['response_vector_rep'].iloc[i]))\n",
        "tags_df['cosine_similarity']=cosines"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3LLTTKuxSgZ4"
      },
      "source": [
        "all_features=[]\n",
        "for i in range(len(tags_df)):\n",
        "  all_features.append(tags_df['word_pos'].iloc[i]+[tags_df['question_sentiment'].iloc[i],tags_df['response_sentiment'].iloc[i],tags_df['cosine_similarity'].iloc[i]])\n",
        "\n",
        "tags_df['features_vector']=all_features\n",
        "\n"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gfd5XWjfhHz2",
        "outputId": "c565b6ad-4bdb-48a7-9640-5e08ac22117b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 849
        }
      },
      "source": [
        "# Modeling all the features\n",
        "train_X,train_Y = tags_df['features_vector'].iloc[:train_size],tags_df['type'].iloc[:train_size]\n",
        "test_X,test_Y = tags_df['features_vector'].iloc[train_size:],tags_df['type'].iloc[train_size:]\n",
        "train_X\n",
        "\n",
        "\n",
        "model_SVC = LinearSVC(random_state=2)\n",
        "model_LR = LogisticRegression(max_iter=1000)\n",
        "model_KNN = KNeighborsClassifier()\n",
        "\n",
        "model_LR.fit(train_X.tolist(), train_Y)\n",
        "model_SVC.fit(train_X.tolist(), train_Y)\n",
        "model_KNN.fit(train_X.tolist(), train_Y)\n",
        "\n",
        "predicted_labels_SVC = model_SVC.predict(test_X.tolist())\n",
        "predicted_labels_LR = model_LR.predict(test_X.tolist())\n",
        "predicted_labels_KNN = model_KNN.predict(test_X.tolist())\n",
        "\n",
        "print (\"SVC Report\")\n",
        "print (confusion_matrix(test_Y,predicted_labels_SVC))\n",
        "print (classification_report(test_Y,predicted_labels_SVC))\n",
        "\n",
        "print (\"Logistic Regression\")\n",
        "print (confusion_matrix(test_Y,predicted_labels_LR))\n",
        "print (classification_report(test_Y,predicted_labels_LR))\n",
        "\n",
        "print (\"KNN\")\n",
        "print (confusion_matrix(test_Y,predicted_labels_KNN))\n",
        "print (classification_report(test_Y,predicted_labels_KNN))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "SVC Report\n",
            "[[306  10   3   1]\n",
            " [ 29  10   0   0]\n",
            " [ 24   9   5   0]\n",
            " [ 10   0   1   2]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.96      0.89       320\n",
            "           1       0.34      0.26      0.29        39\n",
            "           2       0.56      0.13      0.21        38\n",
            "           3       0.67      0.15      0.25        13\n",
            "\n",
            "    accuracy                           0.79       410\n",
            "   macro avg       0.60      0.37      0.41       410\n",
            "weighted avg       0.75      0.79      0.75       410\n",
            "\n",
            "Logistic Regression\n",
            "[[298  12   9   1]\n",
            " [ 25  11   3   0]\n",
            " [ 23   9   6   0]\n",
            " [  8   0   2   3]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.93      0.88       320\n",
            "           1       0.34      0.28      0.31        39\n",
            "           2       0.30      0.16      0.21        38\n",
            "           3       0.75      0.23      0.35        13\n",
            "\n",
            "    accuracy                           0.78       410\n",
            "   macro avg       0.56      0.40      0.44       410\n",
            "weighted avg       0.74      0.78      0.75       410\n",
            "\n",
            "KNN\n",
            "[[280  27  13   0]\n",
            " [ 29   9   1   0]\n",
            " [ 33   1   4   0]\n",
            " [ 11   2   0   0]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.79      0.88      0.83       320\n",
            "           1       0.23      0.23      0.23        39\n",
            "           2       0.22      0.11      0.14        38\n",
            "           3       0.00      0.00      0.00        13\n",
            "\n",
            "    accuracy                           0.71       410\n",
            "   macro avg       0.31      0.30      0.30       410\n",
            "weighted avg       0.66      0.71      0.68       410\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lWH5PqYtgl_m"
      },
      "source": [
        ""
      ],
      "execution_count": 14,
      "outputs": []
    }
  ]
}